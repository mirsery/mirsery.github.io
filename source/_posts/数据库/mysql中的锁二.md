---
title: mysql中的锁二
toc: true
author: mirsery
comments: false
date: 2024-01-30 13:47:18
updated: 2024-01-30 13:47:18
tags:
    - 锁
categories:
    - mysql
excerpt: ‘InnoDB与MyISAM的最大不同有两点：一是支持事务（TRANSACTION）、二是采用了行级锁....’
---


<!-- toc -->


# InnoDB 锁
InnoDB与MyISAM的最大不同有两点：
- 一是支持事务（TRANSACTION）
- 二是采用了行级锁。

## 事务（Transaction）及其ACID属性
事务是由一组SQL语句组成的逻辑处理单元，事务具有4属性，通常称为事务的ACID属性。

- 原性性（Actomicity）：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。
- 一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以操持完整性；事务结束时，所有的内部数据结构（如B树索引或双向链表）也都必须是正确的。
- 隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然。
- 持久性（Durable）：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。

## 事务并发问题
    相对于串行处理来说，并发事务处理能大大增加数据库资源的利用率，提高数据库系统的事务吞吐量，从而可以支持可以支持更多的用户。
并发事务处理也会带来一些问题，主要包括以下几种情况：

1. 更新丢失（Lost Update）
当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题——最后的更新覆盖了其他事务所做的更新。
例如，两个编辑人员制作了同一文档的电子副本。每个编辑人员独立地更改其副本，然后保存更改后的副本，这样就覆盖了原始文档。最后保存其更改保存其更改副本的编辑人员覆盖另一个编辑人员所做的修改。
如果在一个编辑人员完成并提交事务之前，另一个编辑人员不能访问同一文件，则可避免此问题。
2. 脏读（Dirty Reads）
一个事务正在对一条记录做修改，在这个事务并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”的数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做“脏读”。
3. 不可重复读（Non-Repeatable Reads）
 一个事务在读取某些数据已经发生了改变、或某些记录已经被删除了！这种现象叫做“不可重复读”。
4. 幻读（Phantom Reads）
一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。

## 事务隔离级别
在并发事务处理带来的问题中，“更新丢失”通常应该是完全避免的。但防止更新丢失，并不能单靠数据库事务控制器来解决，需要应用程序对要更新的数据加必要的锁来解决，因此，防止更新丢失应该是应用的责任。
“脏读”、“不可重复读”和“幻读”，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决。
数据库实现事务隔离的方式，基本可以分为以下两种。
1. 一种是在读取数据前，对其加锁，阻止其他事务对数据进行修改。
2. 另一种是不用加任何锁，通过一定机制生成一个数据请求时间点的一致性数据快照（Snapshot），并用这个快照来提供一定级别（语句级或事务级）的一致性读取。从用户的角度，好像是数据库可以提供同一数据的多个版本，因此，这种技术叫做数据多版本并发控制（ＭultiVersion Concurrency Control，简称MVCC或MCC），也经常称为多版本数据库。

数据库的事务隔离级别越严格，并发副作用越小，但付出的代价也就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的，同时，不同的应用对读一致性和事务隔离程度的要求也是不同的，比如许多应用对“不可重复读”和“幻读”并不敏感，可能更关心数据并发访问的能力。
为了解决“隔离”与“并发”的矛盾，ISO/ANSI SQL92定义了４个事务隔离级别，每个级别的隔离程度不同，允许出现的副作用也不同，应用可以根据自己业务逻辑要求，通过选择不同的隔离级别来平衡＂隔离＂与＂并发＂的矛盾。


|隔离级别/读数据一致性及允许的并发副作用|读数据一致性|脏读|不可重复读|幻读|
|:---|:---|:---:|:---:|:---:|
|未提交读（Read uncommitted）|最低级别，只能保证不读取物理上损坏的数据|是|是|是|
|已提交读（Read committed）|语句级|否|是|是|
|可重复读（Repeatable read）|事务级|否|否|是|
|可序列化（Serializable）|最高级别事务级|否|否|否|

## 获取InonoDB行锁争用情况

可以通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况：

![](InnoDB_row_lock.png)

如果发现争用比较严重，如Innodb_row_lock_waits和Innodb_row_lock_time_avg的值比较高。
还可以通过设置InnoDB Monitors来进一步观察发生锁冲突的表、数据行等，并分析锁争用的原因。

## InnoDB的行锁模式及加锁方法

InnoDB实现了以下两种类型的**行锁**。
- 共享锁（s）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。
- 排他锁（Ｘ）：允许获取排他锁的事务更新数据，阻止其他事务取得相同的数据集共享读锁和排他写锁。

另外，为了允许行锁和表锁共存，实现多粒度锁机制。InnoDB还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是**表锁**。
- 意向共享锁（IS）：事务打算给数据行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。
- 意向排他锁（IX）：事务打算给数据行加排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。


InnoDB行锁模式兼容性列表

|当前锁模式/是否兼容/请求锁模式|X|IX|S|IS|
|:---|:---:|:---:|:---:|:---:|
|X|冲突|冲突|冲突|冲突|
|IX|冲突|兼容|冲突|兼容|
|S|冲突|冲突|兼容|兼容|
|IS|冲突|兼容|兼容|兼容|

如果一个事务请求的锁模式与当前的锁兼容，InnoDB就请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。意向锁是InnoDB自动加的，不需用户干预。

对于**UPDATE**、**DELETE**和**INSERT**语句，InnoDB会自动给涉及及数据集加排他锁（Ｘ）；

对于普通**SELECT**语句，InnoDB不会加任何锁；

事务可以通过以下语句显示给记录集加共享锁或排锁。
共享锁（Ｓ）：```SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE```
排他锁（X）：```SELECT * FROM table_name WHERE ... FOR UPDATE```

用```SELECT .. IN SHARE MODE```获得共享锁，主要用在需要数据依存关系时确认某行记录是否存在，并确保没有人对这个记录进行UPDATE或者DELETE操作。但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用SELECT ... FOR UPDATE方式获取排他锁。

## InnoDB行锁实现方式
InnoDB行锁是通过**索引上的索引项**来实现的。InnoDB这种行锁实现特点意味者：只有通过索引条件检索数据，InnoDB才会使用行级锁，否则，InnoDB将使用表锁。在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。

## 间隙锁（Next-Key锁）
当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据的索引项加锁；

对于键值在条件范围内但并不存在的记录，叫做“**间隙(GAP)**”，InnoDB也会对这个“**间隙**”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。

举例来说，假如emp表中只有101条记录，其empid的值分别是1,2,...,100,101，下面的SQL：
```sql
    SELECT * FROM emp WHERE empid > 100 FOR UPDATE
```
- **FOR UPDATE**：表示对查询结果进行加锁，其他事务不能修改或删除查询结果中涉及到的行。
- **FOR SHARE**：表示对查询结果进行共享锁，其他事务可以读取查询结果中涉及到的行，但不能修改或删除。

上面 sql 语句是一个范围条件的检索，InnoDB不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁。

InnoDB使用间隙锁的目的：
    - 一方面是为了防止幻读，以满足相关隔离级别的要求；对于上面的例子，要是不使用间隙锁，如果其他事务插入了empid大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；
    - 另一方面，是为了满足其恢复和复制的需要。有关其恢复和复制对机制的影响，以及不同隔离级别下InnoDB使用间隙锁的情况。

> 很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。
> 因此，在实际开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。

## 什么时候使用表锁
对于InnoDB表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们之所以选择InnoDB表的理由。但在个别特殊事务中，也可以考虑使用表级锁。

第一种情况是：事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度。

第二种情况是：事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。

当然，应用中这两种事务不能太多，否则，就应该考虑使用ＭyISAＭ表。
在InnoDB下 ，使用表锁要注意以下两点。
（１） 使用**LOCK TALBES**虽然可以给**InnoDB**加表级锁，但必须说明的是，表锁不是由InnoDB存储引擎层管理的，而是由其上一层ＭySQL Server负责的，仅当autocommit=0、innodb_table_lock=1（默认设置）时，InnoDB层才能知道MySQL加的表锁，ＭySQL Server才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁；否则，InnoDB将无法自动检测并处理这种死锁。
（２） 在用**LOCAK TABLES**对**InnoDB**加锁时要注意，要将**AUTOCOMMIT设为0**，否则ＭySQL不会给表加锁；事务结束前，不要用**UNLOCAK TABLES**释放表锁，因为**UNLOCK TABLES**会隐含地提交事务；
COMMIT或ROLLBACK不能释放用LOCAK TABLES加的表级锁，必须用UNLOCK TABLES释放表锁，正确的方式见如下语句. 例如，如果需要写表t1并从表t读，可以按如下做：
```sql
SET AUTOCOMMIT=0;
LOCAK TABLES t1 WRITE, t2 READ, ...;
[do something with tables t1 and here];
COMMIT;
UNLOCK TABLES;
```

## 关于死锁
在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，这就决定了InnoDB发生死锁是可能的。发生死锁后，InnoDB一般都能自动检测到，并使一个事务释放锁并退回，另一个事务获得锁，继续完成事务。
但在涉及外部锁，或涉及表锁的情况下，InnoDB并不能完全自动检测到死锁，这需要通过设置锁等待超时参数innodb_lock_wait_timeout来解决。
需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获取所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖垮数据库。
我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。通常来说，死锁都是应用设计的问题，通过调整业务流程、数据库对象设计、事务大小、以及访问数据库的SQL语句，绝大部分都可以避免。
下面就通过实例来介绍几种避免死锁的常用方法:
（１） 在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序为访问表，这样可以大大降低产生死锁的机会。如果两个session访问两个表的顺序不同，发生死锁的机会就非常高！但如果以相同的顺序来访问，死锁就可能避免。
（２） 在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低死锁的可能。
（３） 在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应该先申请共享锁，更新时再申请排他锁。
（４） 在**REPEATEABLE-READ**隔离级别下，如果两个线程同时对相同条件记录用```SELECT...ROR UPDATE```加排他锁，在没有符合该记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁。这种情况下，将隔离级别改成```READ COMMITTED```，就可以避免问题。
（５） 当隔离级别为**READ COMMITED**时，如果两个线程都先执行```SELECT...FOR UPDATE```，判断是否存在符合条件的记录，如果没有，就插入记录。此时，只有一个线程能插入成功，另一个线程会出现锁等待，当第１个线程提交后，第２个线程会因主键重出错，但虽然这个线程出错了，却会获得一个排他锁！这时如果有第３个线程又来申请排他锁，也会出现死锁。对于这种情况，可以直接做插入操作，然后再捕获主键重异常，或者在遇到主键重错误时，总是执行ROLLBACK释放获得的排他锁。
 
尽管通过上面的设计和优化等措施，可以大减少死锁，但死锁很难完全避免。因此，在程序设计中总是捕获并处理死锁异常是一个很好的编程习惯。
如果出现死锁，可以用SHOW INNODB STATUS命令来确定最后一个死锁产生的原因和改进措施。

## 总结
对于InnoDB表，主要有以下几点:
（１） InnoDB的行锁是基于索引实现的，如果不通过索引访问数据，InnoDB会使用表锁。
（２） InnoDB间隙锁机制，以及InnoDB使用间隙锁的原因。
（３） 在不同的隔离级别下，InnoDB的锁机制和一致性读策略不同。
（４） ＭySQL的恢复和复制对InnoDB锁机制和一致性读策略也有较大影响。
（５） 锁冲突甚至死锁很难完全避免。

在了解InnoDB的锁特性后，用户可以通过设计和SQL调整等措施减少锁冲突和死锁，包括：
1.  尽量使用较低的隔离级别
2.  精心设计索引，并尽量使用索引访问数据，使加锁更精确，从而减少锁冲突的机会。
3.  选择合理的事务大小，小事务发生锁冲突的几率也更小。
4.  给记录集显示加锁时，最好一次性请求足够级别的锁。比如要修改数据的话，最好直接申请排他锁，而不是先申请共享锁，修改时再请求排他锁，这样容易产生死锁。
5.  不同的程序访问一组表时，应尽量约定以相同的顺序访问各表，对一个表而言，尽可能以固定的顺序存取表中的行。这样可以大减少死锁的机会。
6.  尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响。
7.  不要申请超过实际需要的锁级别；除非必须，查询时不要显示加锁。
8.  对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能。