<!DOCTYPE html><html lang="zh-cn"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 基于 LeNet5 的 MNIST 手写数字识别模型 · mirsery</title><meta name="description" content="基于 LeNet5 的 MNIST 手写数字识别模型 - mirsery"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/css/prontera.css"><link rel="stylesheet" href="/css/dracula.css"><link rel="search" type="application/opensearchdescription+xml" href="https://mirsery.github.io/atom.xml" title="mirsery"><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="mirsery" type="application/atom+xml">
</head><body><header class="feature-header"><nav class="component-nav"><ul><div class="logo-container"><a href="/"><h2 class="title">mirsery</h2></a></div><a class="li component-nav-item" href="/" target="_self"><p>HOME</p></a><a class="li component-nav-item" href="/archives" target="_self"><p>ARCHIVES</p></a><a class="li component-nav-item" href="/categories" target="_self"><p>CATEGORIES</p></a><a class="li component-nav-item" href="/tags" target="_self"><p>TAGS</p></a><ul class="shortcut-icons"><a href="https://github.com/mirsery" target="_blank"><img class="icon" src="/images/github.svg"></a><a href="/atom.xml" target="_blank"><img class="icon" src="/images/rss.svg"></a><a href="https://www.zhihu.com/people/mirsery" target="_blank"><img class="icon" src="/images/zhihu.svg"></a></ul></ul></nav></header><main class="container"><div id="post-container"><div class="post article post-block"><h1 class="post-title">基于 LeNet5 的 MNIST 手写数字识别模型</h1><div class="post-info">2016年12月1日</div><div class="post-content"><p>源码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding: utf-8</span><br><br><span class="hljs-comment"># 基于 LeNet5 的 MNIST 手写数字识别模型</span><br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> random<br><span class="hljs-comment">#import tensorflow as tf</span><br><span class="hljs-keyword">from</span> tensorflow.examples.tutorials.mnist <span class="hljs-keyword">import</span> input_data<br><br><span class="hljs-keyword">import</span> tensorflow.compat.v1 <span class="hljs-keyword">as</span> tf<br>tf.disable_v2_behavior()<br><br><span class="hljs-comment"># 数据集路径</span><br>data_dir=<span class="hljs-string">&#x27;./data/mnist&#x27;</span><br><br><span class="hljs-comment"># 自动下载 MNIST 数据集</span><br>mnist = input_data.read_data_sets(data_dir, one_hot=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># 如果自动下载失败，则手工从官网上下载 MNIST 数据集，然后进行加载</span><br><span class="hljs-comment"># 下载地址  http://yann.lecun.com/exdb/mnist/</span><br><span class="hljs-comment">#mnist=input_data.read_data_sets(data_dir,one_hot=True)</span><br><br><span class="hljs-comment"># 提取训练集、测试集</span><br>train_xdata=mnist.train.images<br>test_xdata=mnist.test.images<br><br><span class="hljs-comment"># 提取标签数据</span><br>train_labels=mnist.train.labels<br>test_labels=mnist.test.labels<br><br><span class="hljs-comment"># 训练数据，占位符</span><br>x = tf.placeholder(<span class="hljs-string">&quot;float&quot;</span>, shape=[<span class="hljs-literal">None</span>, <span class="hljs-number">784</span>])<br><span class="hljs-comment"># 训练的标签数据，占位符</span><br>y_ = tf.placeholder(<span class="hljs-string">&quot;float&quot;</span>, shape=[<span class="hljs-literal">None</span>, <span class="hljs-number">10</span>])<br><span class="hljs-comment"># 将样本数据转为28x28</span><br>x_image = tf.reshape(x, [-<span class="hljs-number">1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>])<br><br><span class="hljs-comment"># 保留概率，用于 dropout 层</span><br>keep_prob = tf.placeholder(tf.float32)<br><br><span class="hljs-comment"># 模型的相关参数</span><br>step_cnt=<span class="hljs-number">10000</span>          <span class="hljs-comment"># 训练模型的迭代次数</span><br>batch_size=<span class="hljs-number">100</span>          <span class="hljs-comment"># 每次迭代时，批量获取样本的数据量</span><br>learning_rate=<span class="hljs-number">0.001</span>     <span class="hljs-comment"># 学习率</span><br><br><span class="hljs-comment"># 模型保存路径</span><br>model_dir=<span class="hljs-string">&#x27;./model/mnist&#x27;</span><br><br><span class="hljs-comment"># LeNet5 网络模型</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lenet_network</span>():</span><br>		<span class="hljs-comment"># 第一层：卷积层</span><br>		<span class="hljs-comment"># 卷积核尺寸为5x5，通道数为1，深度为32，移动步长为1，采用ReLU激励函数</span><br>		conv1_weights = tf.get_variable(<span class="hljs-string">&quot;conv1_weights&quot;</span>, [<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">32</span>], initializer=tf.truncated_normal_initializer(stddev=<span class="hljs-number">0.1</span>))<br>		conv1_biases = tf.get_variable(<span class="hljs-string">&quot;conv1_biases&quot;</span>, [<span class="hljs-number">32</span>], initializer=tf.constant_initializer(<span class="hljs-number">0.0</span>))<br>		conv1 = tf.nn.conv2d(x_image, conv1_weights, strides=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">&#x27;SAME&#x27;</span>)<br>		relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))<br><br>		<span class="hljs-comment"># 第二层：最大池化层</span><br>		<span class="hljs-comment"># 池化核的尺寸为2x2，移动步长为2，使用全0填充</span><br>		pool1 = tf.nn.max_pool(relu1, ksize=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], strides=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">&#x27;SAME&#x27;</span>)<br><br>		<span class="hljs-comment"># 第三层：卷积层</span><br>		<span class="hljs-comment"># 卷积核尺寸为5x5，通道数为32，深度为64，移动步长为1，采用ReLU激励函数</span><br>		conv2_weights = tf.get_variable(<span class="hljs-string">&quot;conv2_weights&quot;</span>, [<span class="hljs-number">5</span>, <span class="hljs-number">5</span>, <span class="hljs-number">32</span>, <span class="hljs-number">64</span>], initializer=tf.truncated_normal_initializer(stddev=<span class="hljs-number">0.1</span>))<br>		conv2_biases = tf.get_variable(<span class="hljs-string">&quot;conv2_biases&quot;</span>, [<span class="hljs-number">64</span>], initializer=tf.constant_initializer(<span class="hljs-number">0.0</span>))<br>		conv2 = tf.nn.conv2d(pool1, conv2_weights, strides=[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">&#x27;SAME&#x27;</span>)<br>		relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))<br><br>		<span class="hljs-comment"># 第四层：最大池化层</span><br>		<span class="hljs-comment"># 池化核尺寸为2x2, 移动步长为2，使用全0填充</span><br>		pool2 = tf.nn.max_pool(relu2, ksize=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], strides=[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>], padding=<span class="hljs-string">&#x27;SAME&#x27;</span>)<br><br>		<span class="hljs-comment"># 第五层：全连接层</span><br>		fc1_weights = tf.get_variable(<span class="hljs-string">&quot;fc1_weights&quot;</span>, [<span class="hljs-number">7</span> * <span class="hljs-number">7</span> * <span class="hljs-number">64</span>, <span class="hljs-number">1024</span>],<br>																	initializer=tf.truncated_normal_initializer(stddev=<span class="hljs-number">0.1</span>))<br>		fc1_baises = tf.get_variable(<span class="hljs-string">&quot;fc1_baises&quot;</span>, [<span class="hljs-number">1024</span>], initializer=tf.constant_initializer(<span class="hljs-number">0.1</span>))<br>		pool2_vector = tf.reshape(pool2, [-<span class="hljs-number">1</span>, <span class="hljs-number">7</span> * <span class="hljs-number">7</span> * <span class="hljs-number">64</span>])<br>		fc1 = tf.nn.relu(tf.matmul(pool2_vector, fc1_weights) + fc1_baises)<br><br>		<span class="hljs-comment"># Dropout层（即按keep_prob的概率保留数据，其它丢弃），以防止过拟合</span><br>		fc1_dropout = tf.nn.dropout(fc1, keep_prob)<br><br>		<span class="hljs-comment"># 第六层：全连接层</span><br>		fc2_weights = tf.get_variable(<span class="hljs-string">&quot;fc2_weights&quot;</span>, [<span class="hljs-number">1024</span>, <span class="hljs-number">10</span>],<br>																	initializer=tf.truncated_normal_initializer(stddev=<span class="hljs-number">0.1</span>))  <span class="hljs-comment"># 神经元节点数1024, 分类节点10</span><br>		fc2_biases = tf.get_variable(<span class="hljs-string">&quot;fc2_biases&quot;</span>, [<span class="hljs-number">10</span>], initializer=tf.constant_initializer(<span class="hljs-number">0.1</span>))<br>		fc2 = tf.matmul(fc1_dropout, fc2_weights) + fc2_biases<br><br>		<span class="hljs-comment"># 第七层：输出层</span><br>		y_conv = tf.nn.softmax(fc2)<br><br>		<span class="hljs-keyword">return</span> y_conv<br><br><span class="hljs-comment"># 训练模型</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train_model</span>():</span><br><br>		<span class="hljs-comment"># 加载 LeNet5 网络结构</span><br>		y_conv=lenet_network()<br><br>		<span class="hljs-comment"># 定义交叉熵损失函数</span><br>		<span class="hljs-comment"># y_ 为真实标签</span><br>		cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[<span class="hljs-number">1</span>]))<br><br>		<span class="hljs-comment"># 选择优化器，使优化器最小化损失函数</span><br>		train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)<br><br>		<span class="hljs-comment"># 返回模型预测的最大概率的结果，并与真实值作比较</span><br>		correct_prediction = tf.equal(tf.argmax(y_conv, <span class="hljs-number">1</span>), tf.argmax(y_, <span class="hljs-number">1</span>))<br><br>		<span class="hljs-comment"># 用平均值来统计测试准确率</span><br>		accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))<br><br>		<span class="hljs-comment"># 训练模型</span><br>		saver=tf.train.Saver()<br>		<span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>				tf.global_variables_initializer().run()<br><br>				<span class="hljs-keyword">for</span> step <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(step_cnt):<br>						batch = mnist.train.next_batch(batch_size)<br>						<span class="hljs-keyword">if</span> step % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>			    <span class="hljs-comment"># 每迭代100步进行一次评估，输出结果，保存模型，便于及时了解模型训练进展</span><br>								train_accuracy = accuracy.<span class="hljs-built_in">eval</span>(feed_dict=&#123;x: batch[<span class="hljs-number">0</span>], y_: batch[<span class="hljs-number">1</span>], keep_prob: <span class="hljs-number">1.0</span>&#125;)<br>								<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;step %d, training accuracy %g&quot;</span> % (step, train_accuracy))<br>								saver.save(sess,model_dir+<span class="hljs-string">&#x27;/my_mnist_model.ctpk&#x27;</span>,global_step=step)<br>						train_step.run(feed_dict=&#123;x: batch[<span class="hljs-number">0</span>], y_: batch[<span class="hljs-number">1</span>], keep_prob: <span class="hljs-number">0.8</span>&#125;)<br><br>				<span class="hljs-comment"># 使用测试数据测试准确率</span><br>				test_acc=accuracy.<span class="hljs-built_in">eval</span>(feed_dict=&#123;x: test_xdata, y_: test_labels, keep_prob: <span class="hljs-number">1.0</span>&#125;)<br>				<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;test accuracy %g&quot;</span> %test_acc)<br><br><br><span class="hljs-comment"># 模型测试应用</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">test_model</span>():</span><br><br>				<span class="hljs-comment"># 加载 LeNet5 网络结构</span><br>				y_conv = lenet_network()<br><br>				<span class="hljs-comment"># 加载 MNIST 模型</span><br>				saver = tf.train.Saver()<br>				<span class="hljs-keyword">with</span> tf.Session() <span class="hljs-keyword">as</span> sess:<br>						saver.restore(sess, tf.train.latest_checkpoint(model_dir))<br><br>						<span class="hljs-comment"># 随机提取 MNIST 测试集的一个样本数据和标签</span><br>						test_len=<span class="hljs-built_in">len</span>(mnist.test.images)<br>						test_idx=random.randint(<span class="hljs-number">0</span>,test_len-<span class="hljs-number">1</span>)<br>						x_image=mnist.test.images[test_idx]<br>						y=np.argmax(mnist.test.labels[test_idx])<br><br>						<span class="hljs-comment"># 跑模型进行识别</span><br>						y_conv = tf.argmax(y_conv,<span class="hljs-number">1</span>)<br>						pred=sess.run(y_conv,feed_dict=&#123;x:[x_image], keep_prob: <span class="hljs-number">1.0</span>&#125;)<br><br>						<span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;正确：&#x27;</span>,y,<span class="hljs-string">&#x27;，预测：&#x27;</span>,pred[<span class="hljs-number">0</span>])<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br><br>		<span class="hljs-comment"># 训练模型</span><br>		train_model()<br><br>		<span class="hljs-comment"># 测试应用模型</span><br>		<span class="hljs-comment">#test_model()</span><br></code></pre></td></tr></table></figure></div></div><div id="disqus_thread"></div></div><script>var disqus_shortname = 'mirsery';
var disqus_identifier = '2016/12/01/机器学习/基于LetNet5的手写数字识别模型/';
var disqus_title = '基于 LeNet5 的 MNIST 手写数字识别模型';
var disqus_url = 'https://mirsery.github.io/2016/12/01/机器学习/基于LetNet5的手写数字识别模型/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//#{theme.disqus}.disqus.com/count.js" async></script></main><footer class="footer-container"><div class="paginator"><a class="prev" href="/2016/12/01/%E5%89%8D%E7%AB%AF/ES6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201-ES6%E7%AE%80%E4%BB%8Blet%E5%92%8Cconst/">上一篇</a><a class="next" href="/2016/11/24/java/2016/javad%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%88%9B%E5%BB%BA/">下一篇</a></div><div class="copyright"><p>© 2015 - 2021 <a href="https://mirsery.github.io">mirsery</a> </p><p>powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and  <a href="https://github.com/AngryPowman/hexo-theme-prontera" target="_blank">hexo-theme-prontera</a></p></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"mirsery",'auto');ga('send','pageview');</script></body></html>